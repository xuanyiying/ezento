# 系统设计：高并发与高可用

## 一、整体架构

### 1.1 系统架构图

```
┌─────────────┐
│   用户端    │
│  (React)    │
└──────┬──────┘
       │ HTTPS
       ↓
┌─────────────────────────────────────┐
│         Nginx (负载均衡)             │
└──────┬──────────────────────────────┘
       │
       ├──→ WebSocket (实时通信)
       │
       ↓
┌─────────────────────────────────────┐
│      NestJS Backend (多实例)         │
│  ┌──────────────────────────────┐   │
│  │  API Gateway (限流/鉴权)      │   │
│  └──────────────────────────────┘   │
│  ┌──────────────────────────────┐   │
│  │  Agent Module (AI逻辑)       │   │
│  └──────────────────────────────┘   │
│  ┌──────────────────────────────┐   │
│  │  RAG Module (检索增强)       │   │
│  └──────────────────────────────┘   │
└──────┬──────────────────────────────┘
       │
       ├──→ PostgreSQL (主从复制)
       ├──→ MongoDB (分片集群)
       ├──→ Redis (哨兵模式)
       ├──→ ChromaDB (向量数据库)
       ├──→ Bull Queue (消息队列)
       └──→ External APIs (OpenAI, etc)
```

### 1.2 技术栈

```typescript
// 后端
- 框架: NestJS (Node.js)
- 语言: TypeScript
- 数据库: PostgreSQL (结构化) + MongoDB (文档)
- 缓存: Redis (单点 + 集群)
- 消息队列: Bull (基于Redis)
- 向量数据库: ChromaDB
- 监控: Prometheus + Grafana
- 日志: Winston + ELK
- 追踪: Jaeger (分布式追踪)

// 前端
- 框架: React 18
- 状态管理: Redux Toolkit
- UI: Ant Design
- 实时通信: Socket.io

// 基础设施
- 容器: Docker
- 编排: Kubernetes (可选)
- CI/CD: GitHub Actions
- 云服务: AWS (S3, CloudFront)
```

---

## 二、高并发设计

### 2.1 负载均衡

```nginx
# nginx.conf
upstream backend {
    # 负载均衡策略
    least_conn;  # 最少连接数

    server backend1:3000 weight=3 max_fails=3 fail_timeout=30s;
    server backend2:3000 weight=3 max_fails=3 fail_timeout=30s;
    server backend3:3000 weight=2 max_fails=3 fail_timeout=30s;

    # 健康检查
    check interval=3000 rise=2 fall=3 timeout=1000;
}

server {
    listen 80;
    server_name api.example.com;

    # 限流
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    limit_req zone=api_limit burst=200 nodelay;

    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;

        # 超时设置
        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # 请求头
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # WebSocket支持
    location /socket.io/ {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### 2.2 API 限流

```typescript
import { Injectable } from "@nestjs/common";
import { Redis } from "ioredis";

@Injectable()
export class RateLimiter {
  constructor(private redis: Redis) {}

  // 令牌桶算法
  async checkLimit(
    key: string,
    limit: number,
    window: number
  ): Promise<boolean> {
    const now = Date.now();
    const windowStart = now - window * 1000;

    // 使用Redis的ZSET实现滑动窗口
    const multi = this.redis.multi();

    // 1. 删除过期的请求
    multi.zremrangebyscore(key, 0, windowStart);

    // 2. 添加当前请求
    multi.zadd(key, now, `${now}-${Math.random()}`);

    // 3. 统计窗口内的请求数
    multi.zcard(key);

    // 4. 设置过期时间
    multi.expire(key, window);

    const results = await multi.exec();
    const count = results[2][1] as number;

    return count <= limit;
  }

  // 使用装饰器
  @RateLimit({ limit: 100, window: 60 })
  async someEndpoint() {
    // ...
  }
}

// 装饰器实现
export function RateLimit(options: { limit: number; window: number }) {
  return function (
    target: any,
    propertyKey: string,
    descriptor: PropertyDescriptor
  ) {
    const originalMethod = descriptor.value;

    descriptor.value = async function (...args: any[]) {
      const limiter = this.rateLimiter;
      const userId = this.request.user?.id || this.request.ip;
      const key = `ratelimit:${propertyKey}:${userId}`;

      const allowed = await limiter.checkLimit(
        key,
        options.limit,
        options.window
      );

      if (!allowed) {
        throw new HttpException(
          "Too Many Requests",
          HttpStatus.TOO_MANY_REQUESTS
        );
      }

      return originalMethod.apply(this, args);
    };

    return descriptor;
  };
}
```

### 2.3 缓存策略

```typescript
// 三级缓存
export class CacheService {
  constructor(private redis: Redis, private localCache: NodeCache) {}

  async get(key: string): Promise<any> {
    // Level 1: 本地缓存 (最快，但不共享)
    let value = this.localCache.get(key);
    if (value) {
      console.log("本地缓存命中");
      return value;
    }

    // Level 2: Redis缓存 (共享，较快)
    value = await this.redis.get(key);
    if (value) {
      console.log("Redis缓存命中");
      this.localCache.set(key, value, 60); // 缓存1分钟
      return JSON.parse(value);
    }

    // Level 3: 数据库 (最慢)
    console.log("缓存未命中，查询数据库");
    return null;
  }

  async set(key: string, value: any, ttl: number) {
    // 同时写入两级缓存
    this.localCache.set(key, value, ttl);
    await this.redis.set(key, JSON.stringify(value), "EX", ttl);
  }

  async invalidate(key: string) {
    // 同时清除两级缓存
    this.localCache.del(key);
    await this.redis.del(key);
  }
}

// 缓存装饰器
export function Cacheable(options: { ttl: number; key?: string }) {
  return function (
    target: any,
    propertyKey: string,
    descriptor: PropertyDescriptor
  ) {
    const originalMethod = descriptor.value;

    descriptor.value = async function (...args: any[]) {
      const cacheKey = options.key || `${propertyKey}:${JSON.stringify(args)}`;
      const cache = this.cacheService;

      // 尝试从缓存获取
      const cached = await cache.get(cacheKey);
      if (cached) {
        return cached;
      }

      // 执行原方法
      const result = await originalMethod.apply(this, args);

      // 写入缓存
      await cache.set(cacheKey, result, options.ttl);

      return result;
    };

    return descriptor;
  };
}

// 使用示例
@Injectable()
export class UserService {
  @Cacheable({ ttl: 300, key: "user" })
  async getUserById(id: string) {
    return await this.prisma.user.findUnique({ where: { id } });
  }
}
```

### 2.4 数据库优化

```typescript
// 1. 连接池配置
const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL,
    },
  },
  // 连接池设置
  pool: {
    min: 10,
    max: 100,
    acquireTimeoutMillis: 30000,
    idleTimeoutMillis: 30000,
  },
});

// 2. 索引优化
model User {
  id        String   @id @default(uuid())
  email     String   @unique
  tenantId  String
  createdAt DateTime @default(now())

  @@index([tenantId])           // 单列索引
  @@index([email, tenantId])    // 复合索引
  @@index([createdAt])          // 时间索引
}

// 3. 查询优化
// ❌ N+1查询
const users = await prisma.user.findMany();
for (const user of users) {
  const posts = await prisma.post.findMany({
    where: { userId: user.id }
  });
}

// ✅ 使用include
const users = await prisma.user.findMany({
  include: {
    posts: true
  }
});

// 4. 批量操作
// ❌ 逐个插入
for (const user of users) {
  await prisma.user.create({ data: user });
}

// ✅ 批量插入
await prisma.user.createMany({
  data: users,
  skipDuplicates: true
});

// 5. 分页优化
// ❌ offset分页（大offset很慢）
const users = await prisma.user.findMany({
  skip: 10000,
  take: 20
});

// ✅ cursor分页
const users = await prisma.user.findMany({
  take: 20,
  cursor: { id: lastUserId },
  orderBy: { id: 'asc' }
});
```

### 2.5 异步处理

```typescript
import { Queue, Worker } from "bullmq";

// 创建队列
const aiQueue = new Queue("ai-tasks", {
  connection: {
    host: "localhost",
    port: 6379,
  },
});

// 添加任务
export class ConsultationService {
  async createConsultation(data: any) {
    // 1. 快速响应用户
    const consultation = await this.prisma.consultation.create({
      data: {
        ...data,
        status: "processing",
      },
    });

    // 2. 异步处理AI任务
    await aiQueue.add("analyze", {
      consultationId: consultation.id,
      symptoms: data.symptoms,
    });

    return consultation;
  }
}

// Worker处理任务
const worker = new Worker(
  "ai-tasks",
  async (job) => {
    console.log(`处理任务: ${job.id}`);

    switch (job.name) {
      case "analyze":
        await analyzeSymptoms(job.data);
        break;
      case "generate_report":
        await generateReport(job.data);
        break;
    }
  },
  {
    connection: {
      host: "localhost",
      port: 6379,
    },
    concurrency: 10, // 并发处理10个任务
  }
);

// 任务失败重试
await aiQueue.add("analyze", data, {
  attempts: 3,
  backoff: {
    type: "exponential",
    delay: 1000,
  },
});
```

---

## 三、高可用设计

### 3.1 熔断器模式

```typescript
export class CircuitBreaker {
  private failures = 0;
  private lastFailureTime: number = 0;
  private state: "CLOSED" | "OPEN" | "HALF_OPEN" = "CLOSED";

  constructor(
    private threshold: number = 5, // 失败阈值
    private timeout: number = 60000, // 熔断超时
    private halfOpenTimeout: number = 30000 // 半开超时
  ) {}

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    // 1. 检查熔断器状态
    if (this.state === "OPEN") {
      if (Date.now() - this.lastFailureTime > this.timeout) {
        this.state = "HALF_OPEN";
        console.log("熔断器进入半开状态");
      } else {
        throw new Error("熔断器开启，拒绝请求");
      }
    }

    try {
      // 2. 执行函数
      const result = await fn();

      // 3. 成功，重置计数
      if (this.state === "HALF_OPEN") {
        this.state = "CLOSED";
        console.log("熔断器关闭");
      }
      this.failures = 0;

      return result;
    } catch (error) {
      // 4. 失败，增加计数
      this.failures++;
      this.lastFailureTime = Date.now();

      if (this.failures >= this.threshold) {
        this.state = "OPEN";
        console.log("熔断器开启");
      }

      throw error;
    }
  }
}

// 使用示例
export class AIProviderService {
  private breaker = new CircuitBreaker(5, 60000);

  async callOpenAI(prompt: string) {
    return await this.breaker.execute(async () => {
      return await this.openai.call(prompt);
    });
  }
}
```

### 3.2 降级策略

```typescript
export class DegradationService {
  async callAI(prompt: string): Promise<string> {
    try {
      // 1. 尝试主模型 (GPT-4)
      return await this.callGPT4(prompt);
    } catch (error) {
      console.warn("GPT-4失败，降级到GPT-3.5");

      try {
        // 2. 降级到备用模型 (GPT-3.5)
        return await this.callGPT35(prompt);
      } catch (error) {
        console.warn("GPT-3.5失败，降级到本地模型");

        try {
          // 3. 降级到本地模型
          return await this.callLocalModel(prompt);
        } catch (error) {
          console.error("所有模型失败，返回默认响应");

          // 4. 返回默认响应
          return this.getDefaultResponse();
        }
      }
    }
  }

  private getDefaultResponse(): string {
    return "抱歉，AI服务暂时不可用，请稍后重试或联系人工客服。";
  }
}
```

### 3.3 健康检查

```typescript
@Controller("health")
export class HealthController {
  constructor(
    private prisma: PrismaClient,
    private redis: Redis,
    private aiService: AIService
  ) {}

  @Get()
  async check() {
    const checks = await Promise.allSettled([
      this.checkDatabase(),
      this.checkRedis(),
      this.checkAI(),
      this.checkDisk(),
      this.checkMemory(),
    ]);

    const results = checks.map((check, i) => ({
      name: ["database", "redis", "ai", "disk", "memory"][i],
      status: check.status === "fulfilled" ? "healthy" : "unhealthy",
      details: check.status === "fulfilled" ? check.value : check.reason,
    }));

    const allHealthy = results.every((r) => r.status === "healthy");

    return {
      status: allHealthy ? "healthy" : "unhealthy",
      timestamp: new Date().toISOString(),
      checks: results,
    };
  }

  private async checkDatabase() {
    const start = Date.now();
    await this.prisma.$queryRaw`SELECT 1`;
    const latency = Date.now() - start;

    return {
      latency: `${latency}ms`,
      status: latency < 100 ? "good" : "slow",
    };
  }

  private async checkRedis() {
    const start = Date.now();
    await this.redis.ping();
    const latency = Date.now() - start;

    return {
      latency: `${latency}ms`,
      status: latency < 50 ? "good" : "slow",
    };
  }

  private async checkAI() {
    try {
      await this.aiService.call("test", { timeout: 5000 });
      return { status: "available" };
    } catch (error) {
      return { status: "unavailable", error: error.message };
    }
  }

  private async checkDisk() {
    const usage = await this.getDiskUsage();
    return {
      usage: `${usage}%`,
      status: usage < 80 ? "good" : "warning",
    };
  }

  private async checkMemory() {
    const usage = process.memoryUsage();
    const usedMB = Math.round(usage.heapUsed / 1024 / 1024);
    const totalMB = Math.round(usage.heapTotal / 1024 / 1024);

    return {
      used: `${usedMB}MB`,
      total: `${totalMB}MB`,
      percentage: `${Math.round((usedMB / totalMB) * 100)}%`,
    };
  }
}
```

### 3.4 监控告警

```typescript
import { Registry, Counter, Histogram, Gauge } from "prom-client";

export class MetricsService {
  private register = new Registry();

  // HTTP请求计数
  private httpRequests = new Counter({
    name: "http_requests_total",
    help: "Total HTTP requests",
    labelNames: ["method", "path", "status"],
    registers: [this.register],
  });

  // HTTP请求延迟
  private httpDuration = new Histogram({
    name: "http_request_duration_ms",
    help: "HTTP request duration",
    labelNames: ["method", "path"],
    buckets: [10, 50, 100, 200, 500, 1000, 2000, 5000],
    registers: [this.register],
  });

  // AI调用计数
  private aiCalls = new Counter({
    name: "ai_calls_total",
    help: "Total AI calls",
    labelNames: ["provider", "model", "status"],
    registers: [this.register],
  });

  // 数据库连接数
  private dbConnections = new Gauge({
    name: "db_connections",
    help: "Database connections",
    registers: [this.register],
  });

  // 记录HTTP请求
  recordHttpRequest(
    method: string,
    path: string,
    status: number,
    duration: number
  ) {
    this.httpRequests.inc({ method, path, status });
    this.httpDuration.observe({ method, path }, duration);
  }

  // 记录AI调用
  recordAICall(provider: string, model: string, status: "success" | "error") {
    this.aiCalls.inc({ provider, model, status });
  }

  // 获取指标
  async getMetrics() {
    return await this.register.metrics();
  }
}

// 中间件
export function metricsMiddleware(metrics: MetricsService) {
  return (req, res, next) => {
    const start = Date.now();

    res.on("finish", () => {
      const duration = Date.now() - start;
      metrics.recordHttpRequest(
        req.method,
        req.route?.path || req.path,
        res.statusCode,
        duration
      );
    });

    next();
  };
}
```

---

## 四、性能优化

### 4.1 数据库连接池

```typescript
// PostgreSQL连接池
const pool = new Pool({
  host: "localhost",
  port: 5432,
  database: "mydb",
  user: "user",
  password: "password",
  min: 10, // 最小连接数
  max: 100, // 最大连接数
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});
```

### 4.2 CDN 加速

```typescript
// 静态资源上传到S3 + CloudFront
export class StorageService {
  async uploadFile(file: Express.Multer.File) {
    // 1. 上传到S3
    const key = `uploads/${Date.now()}-${file.originalname}`;
    await this.s3
      .upload({
        Bucket: "my-bucket",
        Key: key,
        Body: file.buffer,
        ContentType: file.mimetype,
        CacheControl: "max-age=31536000", // 缓存1年
      })
      .promise();

    // 2. 返回CDN URL
    return `https://cdn.example.com/${key}`;
  }
}
```

### 4.3 压缩

```typescript
import compression from "compression";

// 启用gzip压缩
app.use(
  compression({
    filter: (req, res) => {
      if (req.headers["x-no-compression"]) {
        return false;
      }
      return compression.filter(req, res);
    },
    level: 6, // 压缩级别 0-9
  })
);
```

---

## 五、面试高频问题

**Q: 如何设计一个支持 10 万 QPS 的系统？**

A: "我会从四个方面优化:

**1. 水平扩展**:

- 多实例部署（10+节点）
- Nginx 负载均衡
- 无状态设计，便于扩展

**2. 缓存优化**:

- Redis 缓存热点数据（命中率>80%）
- 本地缓存减少网络开销
- CDN 加速静态资源

**3. 异步处理**:

- 消息队列削峰填谷
- 耗时操作异步化
- 快速响应用户

**4. 数据库优化**:

- 读写分离
- 分库分表
- 连接池复用

**实际效果**: 我们系统支撑日均 10 万+请求，峰值 QPS 500，P99 延迟<200ms。"

**Q: 如何保证系统的高可用？**

A: "我们实现了 99.9%的可用性，主要措施:

**1. 冗余部署**:

- 多实例部署（3+节点）
- 数据库主从复制
- Redis 哨兵模式

**2. 故障隔离**:

- 熔断器防止雪崩
- 降级策略保证核心功能
- 超时控制避免阻塞

**3. 监控告警**:

- Prometheus 监控 100+指标
- 告警规则（延迟>1s、错误率>5%）
- 7×24 小时值班

**4. 快速恢复**:

- 健康检查自动摘除故障节点
- 自动重启机制
- 灰度发布降低风险

**结果**: 月度可用性 99.95%，MTTR<5 分钟。"
